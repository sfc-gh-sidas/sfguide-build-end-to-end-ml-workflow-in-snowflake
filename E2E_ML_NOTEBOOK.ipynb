{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79ae8e5-aec2-4276-9443-074c3a614142",
   "metadata": {
    "collapsed": false,
    "name": "md_intro"
   },
   "source": [
    "# ❄️ Building an End to End Machine Learning Workflow in Snowflake ❄️\n",
    "\n",
    "In this Notebook ([on Container Runtime](https://docs.snowflake.com/developer-guide/snowflake-ml/notebooks-on-spcs)), we will develop a machine learning model that accurately predicts the \"mortgage response\" (e.g., loan approval, offer acceptance) based on borrower characteristics and loan details.\n",
    "\n",
    "**Why is this important?**\n",
    "\n",
    "- `Risk Management:` Lenders can better assess the risk of loan default.\n",
    "- `Operational Efficiency:` Automating parts of the approval process.\n",
    "- `Targeted Marketing:` Identifying potential borrowers more effectively.\n",
    "- `Improved Customer Experience:` Streamlining the loan process.\n",
    "\n",
    "We will showcase all the typical steps in a machine learning pipeline using native capabilities in Snowflake through this use case:\n",
    "\n",
    "### 1. `FEATURE ENGINEERING:` Use [Snowflake Feature Store](https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store/overview) to track engineered features\n",
    "- Store feature defintions in a feature store for reproducible computation of ML features\n",
    "      \n",
    "### 2. `MODEL TRAINING:` Train models using OSS XGBoost and Snowflake ML APIs\n",
    "- Baseline OSS XGboost\n",
    "- XGBoost with optimal hyperparameters identified via [Snowflake ML Parallel Hyperparameter Optimization](https://docs.snowflake.com/en/developer-guide/snowflake-ml/container-hpo)\n",
    "\n",
    "### 3. `MODEL LOGGING, INFERENCE, & EXPLAINABILITY:` Register models in [Snowflake Model Registry](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/overview)\n",
    "- Explore model registry capabilities such as **metadata tracking, inference, and explainability**\n",
    "- Compare model metrics on train/test set to identify any issues of model performance or overfitting\n",
    "- Tag the best performing model version as 'default' version\n",
    "\n",
    "### 4. `ML OBSERVABILITY:` Set up [Model Monitors](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/model-observability) to track 1 year of predicted and actual loan repayments\n",
    "- **Compute performance metrics** such a F1, Precision, Recall\n",
    "- **Inspect model drift** (i.e. how much has the average predicted repayment rate changed day-to-day)\n",
    "- **Compare models** side-by-side to understand which model should be used in production\n",
    "- Identify and understand **data issues**\n",
    "\n",
    "### 5. `ML LINEAGE:` Track [data and model lineage](https://docs.snowflake.com/en/user-guide/ui-snowsight-lineage#ml-lineage) throughout\n",
    "- View and understand\n",
    "  - The **origin of the data** used for computed features\n",
    "  - The **data used** for model training\n",
    "  - The **available model versions** being monitored\n",
    "\n",
    "### 6. `[OPTIONAL] DISTRIBUTED MODEL TRAINING & DEPLOYMENT`\n",
    "- Distributed XGBoost via [Snowflake's Distributed Modeling Classes](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/modeling_distributors) - single node, multi-GPU and multi-node, multi-GPU\n",
    "- [Deploy model to Snowpark Container Services](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/container) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503e740-d386-4bfb-89a0-6270311d1321",
   "metadata": {
    "collapsed": false,
    "name": "md_shap"
   },
   "source": [
    "First, the only library we need to install is `shap`, which will be used to understand model explainability later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2512cb5-15ae-40b2-84c7-8a44a9979670",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "pip_install"
   },
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0a5d6-3e4e-406b-a37b-3606e4c8484f",
   "metadata": {
    "collapsed": false,
    "name": "md_version"
   },
   "source": [
    "Let's set a version (must be a string) that will be used through all the artifacts that will be created for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78265b8-8baa-4136-a32a-32f3f620949d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "set_version_num"
   },
   "outputs": [],
   "source": [
    "VERSION_NUM = 'V0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e389e3-947e-49f2-be60-59819c70640f",
   "metadata": {
    "collapsed": false,
    "name": "md_imports"
   },
   "source": [
    "Now, let's import all the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "imports_and_session",
    "resultHeight": 84
   },
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import math\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Third-party\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import sklearn\n",
    "import streamlit as st\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Snowflake ML\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n",
    "from snowflake.ml.runtime_cluster import scale_cluster, get_nodes\n",
    "\n",
    "# Snowpark Core\n",
    "from snowflake.snowpark import DataFrame, Window\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark.functions import (\n",
    "    col,\n",
    "    to_timestamp,\n",
    "    min,\n",
    "    max,\n",
    "    month,\n",
    "    dayofmonth,\n",
    "    dayofweek,\n",
    "    dayofyear,\n",
    "    avg,\n",
    "    date_add,\n",
    "    sql_expr,\n",
    ")\n",
    "from snowflake.snowpark.types import IntegerType\n",
    "\n",
    "# Initialize session\n",
    "session = get_active_session()\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efe5f2-7268-4455-b202-cc99ff12dcb5",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "set_schema"
   },
   "outputs": [],
   "source": [
    "# Use schema DEFAULT_SCHEMA to create new Snowflake objects in this project\n",
    "session.use_schema('DEFAULT_SCHEMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150a19a-9fc5-48ab-8633-4a306ce3097a",
   "metadata": {
    "collapsed": false,
    "name": "md_read_data"
   },
   "source": [
    "We can read the data that's already been pre-loaded into your account as a Snowflake [Snowpark dataframe](https://docs.snowflake.com/en/developer-guide/snowpark/python/working-with-dataframes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e853f0a-321f-4bbd-a69d-44b9b6ad8839",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "read_data"
   },
   "outputs": [],
   "source": [
    "df = session.table(\"MORTGAGE_LENDING_DEMO_DATA\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa46c7d-519b-422c-8932-9b031fc6b4bd",
   "metadata": {
    "collapsed": false,
    "name": "md_feature_eng"
   },
   "source": [
    "# Feature Engineering with Snowpark APIs\n",
    "\n",
    "We will create a number of features within `create_mortgage_features()`:\n",
    "- Timestamp features (i.e. month, day of year, day of week)\n",
    "- Income and Loan features\n",
    "- County-level income stats\n",
    "- High income flag\n",
    "- Time-based rolling average.\n",
    "\n",
    "All the features are created using Snowpark DF operations and functions, which you can find the API reference documentation for [here](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.2.0/index). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b85cc-3bdb-48f9-b562-c67821d65bed",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_features"
   },
   "outputs": [],
   "source": [
    "def create_mortgage_features(df):\n",
    "    # Step 1: Timestamp features (Per-row features)\n",
    "    # Get current date and time\n",
    "    current_time = datetime.now()\n",
    "    df_max_time = datetime.strptime(str(df.select(max(\"TS\")).collect()[0][0]), \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    # Find delta between latest existing timestamp and today's date\n",
    "    timedelta = current_time- df_max_time\n",
    "\n",
    "    df = df.with_columns(\n",
    "        [\"TIMESTAMP\", \"MONTH\", \"DAY_OF_YEAR\", \"DOTW\"],\n",
    "        [\n",
    "            date_add(to_timestamp(\"TS\"), timedelta.days-1),\n",
    "            month(\"TIMESTAMP\"),\n",
    "            dayofyear(\"TIMESTAMP\"),\n",
    "            dayofweek(\"TIMESTAMP\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Step 2: Income and loan features (Per-row features)\n",
    "    df = df.with_columns(\n",
    "        [\"LOAN_AMOUNT\", \"INCOME\", \"INCOME_LOAN_RATIO\"],\n",
    "        [\n",
    "            col(\"LOAN_AMOUNT_000s\")*1000,\n",
    "            col(\"APPLICANT_INCOME_000s\")*1000,\n",
    "            col(\"INCOME\")/col(\"LOAN_AMOUNT\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Step 3: County-level income stats (Per-group features)\n",
    "    county_income_df = df.group_by([\"COUNTY_NAME\"]).agg(\n",
    "        avg(\"INCOME\").alias(\"AVG_COUNTY_INCOME\")\n",
    "    )\n",
    "    # Join back to the original dataframe\n",
    "    df = df.join(county_income_df, \"COUNTY_NAME\")\n",
    "    \n",
    "    # Step 4: Add high income flag\n",
    "    df = df.with_column(\n",
    "        \"HIGH_INCOME_FLAG\", \n",
    "        (col(\"INCOME\") > col(\"AVG_COUNTY_INCOME\")).astype(IntegerType())\n",
    "    )\n",
    "    \n",
    "    # Step 5: Time-based rolling average\n",
    "    df = df.with_column(\n",
    "        \"AVG_THIRTY_DAY_LOAN_AMOUNT\",\n",
    "        sql_expr(\"\"\"\n",
    "            AVG(LOAN_AMOUNT) OVER (\n",
    "                PARTITION BY COUNTY_NAME \n",
    "                ORDER BY TIMESTAMP \n",
    "                RANGE BETWEEN INTERVAL '30 DAYS' PRECEDING AND CURRENT ROW\n",
    "            )\n",
    "        \"\"\")\n",
    "    )\n",
    "\n",
    "    return df\n",
    "    \n",
    "df = create_mortgage_features(df)\n",
    "\n",
    "feature_df = df.select(\n",
    "        [\"LOAN_ID\", \"TIMESTAMP\", \"MONTH\", \"DAY_OF_YEAR\", \"DOTW\", \n",
    "         \"LOAN_AMOUNT\", \"INCOME\", \"INCOME_LOAN_RATIO\", \n",
    "         \"AVG_COUNTY_INCOME\", \"HIGH_INCOME_FLAG\", \n",
    "         \"AVG_THIRTY_DAY_LOAN_AMOUNT\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158412d-bb0c-4793-8f08-be949d6f4134",
   "metadata": {
    "collapsed": false,
    "name": "md_view_features"
   },
   "source": [
    "Let's take a look at the features we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62244827-8252-4153-99c4-087798504b6c",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "view_features"
   },
   "outputs": [],
   "source": [
    "feature_df.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723dbb3-2519-4c56-8c36-c9294f2a3190",
   "metadata": {
    "collapsed": false,
    "name": "md_df_explain"
   },
   "source": [
    "We can even see what the actual SQL execution plan in under the hood from defining all the feature logic above using Snowpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4ead8-25ac-46cc-9bd9-17eac2f796d5",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "df_explain",
    "resultHeight": 312
   },
   "outputs": [],
   "source": [
    "feature_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7645e-e0ac-4539-b132-54ce53431402",
   "metadata": {
    "collapsed": false,
    "name": "md_fs"
   },
   "source": [
    "## Now, we can create a [Snowflake Feature Store](https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store/overview).\n",
    "\n",
    "We'll go ahead and use our session's current Snowflake database, schema, and warehouse to create it for the purpose of this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abacdc71-9f2c-419f-8d50-3e8f89be367f",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_feature_store",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=session.get_current_database(), \n",
    "    name=session.get_current_schema(), \n",
    "    default_warehouse=session.get_current_warehouse(),\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915406f-e52d-4baf-9f6c-b9e0e8d53e6e",
   "metadata": {
    "collapsed": false,
    "name": "md_config_feature_store"
   },
   "source": [
    "A feature store contains feature views. \n",
    "\n",
    "A **feature view** encapsulates a Python or SQL pipeline for transforming raw data into one or more related features. \n",
    "\n",
    "Feature views are organized in the feature store according to the **entities** to which they apply. An **entity** is a higher-level abstraction that represents the subject matter of a feature. \n",
    "\n",
    "So, let's proceed to create a new entity now. Since we are creating features at the loan level, we will create an entity for loans. Entities are used to look up and join features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d6d39-7819-4825-8729-a3f19ca5cdf7",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "load_or_register_entity",
    "resultHeight": 38
   },
   "outputs": [],
   "source": [
    "# First try to retrieve an existing entity definition\n",
    "# If not, define a new one and register\n",
    "try:\n",
    "    # Retrieve existing entity\n",
    "    loan_id_entity = fs.get_entity('LOAN_ENTITY') \n",
    "    print('Retrieved existing entity')\n",
    "except:\n",
    "    # Define new entity\n",
    "    loan_id_entity = Entity(\n",
    "        name = \"LOAN_ENTITY\",\n",
    "        join_keys = [\"LOAN_ID\"],\n",
    "        desc = \"Features defined on a per loan level\")\n",
    "    # Register\n",
    "    fs.register_entity(loan_id_entity)\n",
    "    print(\"Registered new entity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67480d6a-183f-4373-aaa8-d3ed8e80e11d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "list_entities",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "fs.list_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf84fe3-4120-4092-b43d-8873da57d461",
   "metadata": {
    "collapsed": false,
    "name": "md_feature_view"
   },
   "source": [
    "Now, we can create a [Feature View](https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store/feature-views) based on the feature engineering logic we created above and applied to the data we read into a Snowpark DF, which is encapusulated into `feature_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53364f-90c4-45b4-94ee-b2fde6f93475",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "feature_view_creation",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Define and register feature view\n",
    "loan_fv = FeatureView(\n",
    "    name=\"Mortgage_Feature_View\",\n",
    "    entities=[loan_id_entity],\n",
    "    feature_df=feature_df,\n",
    "    timestamp_col=\"TIMESTAMP\",\n",
    "    refresh_freq=\"1 day\",\n",
    "    refresh_mode=\"INCREMENTAL\")\n",
    "\n",
    "# Add feature level descriptions\n",
    "loan_fv = loan_fv.attach_feature_desc(\n",
    "    {\n",
    "        \"MONTH\": \"Month of loan\",\n",
    "        \"DAY_OF_YEAR\": \"Day of calendar year of loan\",\n",
    "        \"DOTW\": \"Day of the week of loan\",\n",
    "        \"LOAN_AMOUNT\": \"Loan amount in $USD\",\n",
    "        \"INCOME\": \"Household income in $USD\",\n",
    "        \"INCOME_LOAN_RATIO\": \"Ratio of LOAN_AMOUNT/INCOME\",\n",
    "        \"AVG_COUNTY_INCOME\": \"Average household income aggregated at county level\",\n",
    "        \"HIGH_INCOME_FLAG\": \"Binary flag to indicate whether household income is higher than MEDIAN_COUNTY_INCOME\",\n",
    "        \"AVG_THIRTY_DAY_LOAN_AMOUNT\": \"Rolling 30 day average of LOAN_AMOUNT\"\n",
    "    }\n",
    ")\n",
    "\n",
    "loan_fv = fs.register_feature_view(loan_fv, version=VERSION_NUM, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2aecb-3593-41ab-8951-3847e707bdaa",
   "metadata": {
    "collapsed": false,
    "name": "md_list_feature_views"
   },
   "source": [
    "Let's take a look at the existing feature views we have in our Feature Store through the Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3225b-b936-4aa7-81f2-27bbaeee1c0f",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_feature_views",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "fs.list_feature_views()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85718b0d-55f0-4013-a4fd-57bdee356322",
   "metadata": {
    "collapsed": false,
    "name": "md_inspect_ui"
   },
   "source": [
    "You can also inspect your feature view in the Feature Store UI link generated in the next cell. \n",
    "\n",
    "You can also click on the `Lineage` tab in the Feature View to look at the lineage of these features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a1aae-0bd2-4aad-b9ed-3347fc56b6ea",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_feature_store_link"
   },
   "outputs": [],
   "source": [
    "# Create link to feature store UI to inspect newly created feature view!\n",
    "org_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\n",
    "account_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\n",
    "db_name = session.sql('SELECT CURRENT_DATABASE()').collect()[0][0]\n",
    "schema_name = session.sql('SELECT CURRENT_SCHEMA()').collect()[0][0]\n",
    "\n",
    "st.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/features/database/{db_name}/store/{schema_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ff67f-bb04-40cb-8c14-11b5ebb2917d",
   "metadata": {
    "collapsed": false,
    "name": "md_dataset"
   },
   "source": [
    "### Retrieve a [Dataset from the feature view for model training](https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store/modeling#generating-snowflake-datasets-for-training)\n",
    "\n",
    "We can now generate a [Snowflake Dataset](https://docs.snowflake.com/en/developer-guide/snowflake-ml/dataset), which are immutable, file-based objects that exist within your Snowpark session. \n",
    "\n",
    "They can be written to persistent Snowflake objects as needed.\n",
    "\n",
    "First, we create a \"spine dataframe\" which will contain the rows and entity IDs that we want to include in our training data. In this example, we are selecting all the rows in our source data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687ccf1-cab1-48b5-a914-f6665cf35a77",
   "metadata": {
    "language": "python",
    "name": "generate_spine_df"
   },
   "outputs": [],
   "source": [
    "# Create a spine dataframe to select the desired rows for training. \n",
    "# In this case we are using all the rows \n",
    "spine_df = df.select(\"LOAN_ID\", \"TIMESTAMP\", \"LOAN_PURPOSE_NAME\",\"MORTGAGERESPONSE\") #only need the features used to fetch rest of feature view\n",
    "spine_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f06788-4a31-4357-83af-e1c1d8bee194",
   "metadata": {
    "collapsed": false,
    "name": "md_generate_dataset"
   },
   "source": [
    "The `generate_dataset()` API will fill this spine_df with the correct feature values from the Feature View."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535efc80-e4fc-41c5-98eb-5b5450bcf199",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "generate_dataset",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "ds = fs.generate_dataset(\n",
    "    name=f\"MORTGAGE_DATASET_EXTENDED_FEATURES_{VERSION_NUM}\",\n",
    "    # only need the features used to fetch rest of feature view\n",
    "    spine_df=df.select(\"LOAN_ID\", \"TIMESTAMP\", \"LOAN_PURPOSE_NAME\",\"MORTGAGERESPONSE\"), \n",
    "    features=[loan_fv],\n",
    "    spine_timestamp_col=\"TIMESTAMP\",\n",
    "    spine_label_cols=[\"MORTGAGERESPONSE\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdaa537-3fb9-476c-9153-3236edfdfcb3",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "convert_dataset_to_snowpark_and_pandas",
    "resultHeight": 239
   },
   "outputs": [],
   "source": [
    "ds_sp = ds.read.to_snowpark_dataframe()\n",
    "ds_sp.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68269d55-c869-41a2-9329-8c47178bba17",
   "metadata": {
    "collapsed": false,
    "name": "md_ohe"
   },
   "source": [
    "Next, we will use [Snowflake ML distributed preprocessors such as OneHotEncoder](https://docs.snowflake.com/en/developer-guide/snowflake-ml/modeling#preprocessing) which are implementations of sklearn preprocessors and run in parallel on the Warehouse. Alternatively you can use OSS sklearn preprocessors directly on the Container Runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e17036-7a69-4915-b025-49c900aeb46b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "one_hot_encoding",
    "resultHeight": 360
   },
   "outputs": [],
   "source": [
    "import snowflake.ml.modeling.preprocessing as snowml\n",
    "from snowflake.snowpark.types import StringType\n",
    "\n",
    "OHE_COLS = ds_sp.select([col.name for col in ds_sp.schema if col.datatype ==StringType()]).columns\n",
    "OHE_POST_COLS = [i+\"_OHE\" for i in OHE_COLS]\n",
    "\n",
    "# Encode categoricals to numeric columns\n",
    "snowml_ohe = snowml.OneHotEncoder(input_cols=OHE_COLS, output_cols = OHE_COLS, drop_input_cols=True)\n",
    "ds_sp_ohe = snowml_ohe.fit(ds_sp).transform(ds_sp)\n",
    "\n",
    "# Rename columns to avoid double nested quotes and white space chars\n",
    "rename_dict = {}\n",
    "for i in ds_sp_ohe.columns:\n",
    "    if '\"' in i:\n",
    "        rename_dict[i] = i.replace('\"','').replace(' ', '_')\n",
    "\n",
    "ds_sp_ohe = ds_sp_ohe.rename(rename_dict)\n",
    "ds_sp_ohe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb14f23-2537-4c0f-85e8-c97368879d9e",
   "metadata": {
    "collapsed": false,
    "name": "md_split_sets"
   },
   "source": [
    "Now, we're ready to split the processed data into train/test sets, fill any null values, and convert the data to pandas to use OSS XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834f6f3-ce15-405e-8fec-1d1bb5c224a6",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "train_test_split",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "train, test = ds_sp_ohe.random_split(weights=[0.70, 0.30], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff103e-5314-4e95-87ba-d784b1102f36",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "fill_na",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "cols = list(ds_sp_ohe.columns)\n",
    "cols.remove(\"TIMESTAMP\")\n",
    "\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917df7f-e277-4fbb-abf5-1a4433367e3b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "convert_data_to_pandas"
   },
   "outputs": [],
   "source": [
    "train_pd = train.to_pandas()\n",
    "test_pd = test.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a295d0-f4a5-48e1-8eab-4d3f67ba5942",
   "metadata": {
    "collapsed": false,
    "name": "md_model_training"
   },
   "source": [
    "# Model Training, Model Logging, Inference, & Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91b35a-8ecb-4a59-b015-f98e06d31e38",
   "metadata": {
    "collapsed": false,
    "name": "md_oss_xgb"
   },
   "source": [
    "## Configure the base OSS XGBoost model & fit the model\n",
    "\n",
    "Let's define and train a model using the OSS `xgboost` library. Note in our imports at the top: `from xgboost import XGBClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4b5fba-b7a8-47ff-aaf6-076b9e78dcaf",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_model",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Define model config\n",
    "xgb_base = XGBClassifier(\n",
    "    max_depth=50,\n",
    "    n_estimators=3,\n",
    "    learning_rate = 0.75,\n",
    "    booster = 'gbtree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f3295-2496-4fd0-ae95-922a78c5b944",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "train_base_model",
    "resultHeight": 1759
   },
   "outputs": [],
   "source": [
    "# Split train data into X, y\n",
    "X_train_pd = train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1) #remove\n",
    "y_train_pd = train_pd.MORTGAGERESPONSE\n",
    "\n",
    "# Train model\n",
    "xgb_base.fit(X_train_pd,y_train_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed8ace-06a4-4e74-a53c-e9a681f602bf",
   "metadata": {
    "collapsed": false,
    "name": "md_measure_baseline"
   },
   "source": [
    "Let's measure the baseline performance of our first version.\n",
    "\n",
    "Note that here, we simply use OSS methods from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ac861-fcf9-47b2-9c11-ec44ee2367e4",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "compute_predictions_and_perf_metrics"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "train_preds_base = xgb_base.predict(X_train_pd)\n",
    "\n",
    "f1_base_train = round(f1_score(y_train_pd, train_preds_base),4)\n",
    "precision_base_train = round(precision_score(y_train_pd, train_preds_base),4)\n",
    "recall_base_train = round(recall_score(y_train_pd, train_preds_base),4)\n",
    "\n",
    "print(f'F1: {f1_base_train} \\nPrecision {precision_base_train} \\nRecall: {recall_base_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93777778-d2ba-42d5-88c4-a90ba18c5006",
   "metadata": {
    "collapsed": false,
    "name": "model_regisry_md",
    "resultHeight": 74
   },
   "source": [
    "## Now, we can log this model to [Snowflake Model Registry](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/overview):\n",
    "\n",
    "- Log models with important metadata\n",
    "- Manage model lifecycles\n",
    "- Serve models from Snowflake runtimes\n",
    "\n",
    "First, we need to create a Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21678e59-deaf-4c2b-b01e-1c59fe31b10a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_model_registry",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "#Create a snowflake model registry object \n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml._internal.utils import identifier\n",
    "from snowflake.ml.model import model_signature\n",
    "\n",
    "db = identifier._get_unescaped_name(session.get_current_database())\n",
    "schema = identifier._get_unescaped_name(session.get_current_schema())\n",
    "\n",
    "# Define model name\n",
    "model_name = f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\"\n",
    "\n",
    "# Create a registry to log the model to\n",
    "model_registry = Registry(session=session, \n",
    "                          database_name=db, \n",
    "                          schema_name=schema,\n",
    "                          options={\"enable_monitoring\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b784b108-20fe-4676-8f01-a814b169f2b1",
   "metadata": {
    "collapsed": false,
    "name": "md_log_model"
   },
   "source": [
    "Now, we can log our model along with all the calculated metrics and other metadata such as model comment (description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41c3ac-49f0-4fd9-a557-9d8eb633f602",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "register_model_version",
    "resultHeight": 229
   },
   "outputs": [],
   "source": [
    "# Deploy the base model to the model registry\n",
    "base_version_name = 'XGB_BASE'\n",
    "\n",
    "try:\n",
    "    mv_base = model_registry.get_model(model_name).version(base_version_name)\n",
    "    print(\"Found existing model version!\")\n",
    "except:\n",
    "    print(\"Logging new model version...\")\n",
    "    mv_base = model_registry.log_model(\n",
    "        model_name=model_name,\n",
    "        model=xgb_base, \n",
    "        version_name=base_version_name,\n",
    "        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100), #using snowpark df to maintain lineage\n",
    "        comment = \"\"\"ML model for predicting loan approval likelihood.\n",
    "                    This model was trained using  xgboost classifier.\n",
    "                    Hyperparameters used were:a\n",
    "                    max_depth=50, n_estimators=3, learning_rate = 0.75, algorithm = gbtree.\n",
    "                    \"\"\",\n",
    "        options = {'relax_version': True},\n",
    "        target_platforms= {\"WAREHOUSE\"}\n",
    "    )\n",
    "    mv_base.set_metric(metric_name=\"Train_F1_Score\", value=f1_base_train)\n",
    "    mv_base.set_metric(metric_name=\"Train_Precision_Score\", value=precision_base_train)\n",
    "    mv_base.set_metric(metric_name=\"Train_Recall_score\", value=recall_base_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dfa38c-3249-4589-b0ee-4f06b9d2f9fd",
   "metadata": {
    "collapsed": false,
    "name": "md_tagging"
   },
   "source": [
    "Let's set this base model as our `DEV` model by using model tagging. We'll also create a `PROD` tag to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b61f2-a79e-4fac-a348-bd05d762154c",
   "metadata": {
    "language": "python",
    "name": "create_tags"
   },
   "outputs": [],
   "source": [
    "# Create tag for DEV model\n",
    "session.sql(\"CREATE OR REPLACE TAG DEV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e277109-3b5e-4df2-84a9-bcb56d2f6201",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_PROD_tag"
   },
   "outputs": [],
   "source": [
    "# Create tag for PROD model\n",
    "session.sql(\"CREATE OR REPLACE TAG PROD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0054df-0cd9-4e81-98b8-6564be86b4b9",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "apply_DEV_tag"
   },
   "outputs": [],
   "source": [
    "# Apply tag\n",
    "m = model_registry.get_model(model_name)\n",
    "m.set_tag(\"DEV\", base_version_name)\n",
    "m.comment = \"Loan approval prediction models\" # Set model level comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783dcf1-1a33-4a9b-97af-0081d1ad9f24",
   "metadata": {
    "collapsed": false,
    "name": "md_reg_functions"
   },
   "source": [
    "The next few cells demonstrate different functions available to us to see our existing models, their versions, metadata such as metrics, and available model functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e294e-929d-4399-b2bb-d5d2d1dd043e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_models",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "model_registry.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dfb281-9751-48a1-a76e-43ffffd9d099",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_model_versions",
    "resultHeight": 146
   },
   "outputs": [],
   "source": [
    "model_registry.get_model(model_name).show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af8a1-7a92-455e-b9a1-8f2c699dfdeb",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "print_model_version_and_metrics",
    "resultHeight": 239
   },
   "outputs": [],
   "source": [
    "print(mv_base)\n",
    "print(mv_base.show_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecdf05c-b3b5-4755-bdff-fd187ef07f58",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "show_model_functions",
    "resultHeight": 2133
   },
   "outputs": [],
   "source": [
    "mv_base.show_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380812c0-1a3a-49a4-a496-040fd1487f7e",
   "metadata": {
    "collapsed": false,
    "name": "md_pred_from_reg"
   },
   "source": [
    "Let's now test running inference on our test set using our logged model in the Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf495261-a8a7-46be-b9c8-3f099268d154",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "predict_from_registry",
    "resultHeight": 351
   },
   "outputs": [],
   "source": [
    "reg_preds = mv_base.run(test, function_name = \"predict\")\n",
    "reg_preds = reg_preds.rename(col('\"output_feature_0\"'), \"MORTGAGE_PREDICTION\")\n",
    "reg_preds.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef61447-10e7-4a38-a429-3da3facf9ce7",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "compute_test_metrics"
   },
   "outputs": [],
   "source": [
    "preds_pd = reg_preds.select([\"MORTGAGERESPONSE\", \"MORTGAGE_PREDICTION\"]).to_pandas()\n",
    "f1_base_test = round(f1_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n",
    "precision_base_test = round(precision_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n",
    "recall_base_test = round(recall_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n",
    "\n",
    "# Log metrics to model registry model\n",
    "mv_base.set_metric(metric_name=\"Test_F1_Score\", value=f1_base_test)\n",
    "mv_base.set_metric(metric_name=\"Test_Precision_Score\", value=precision_base_test)\n",
    "mv_base.set_metric(metric_name=\"Test_Recall_score\", value=recall_base_test)\n",
    "\n",
    "print(f'F1: {f1_base_test} \\nPrecision {precision_base_test} \\nRecall: {recall_base_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b477885-35ce-486d-9e86-7d0cc9d48454",
   "metadata": {
    "collapsed": false,
    "name": "md_hpo"
   },
   "source": [
    "### Oh no! Our model's performance seems to have dropped off significantly from training to our test set. \n",
    "\n",
    "### This is evidence that our model is overfit - can we fix this with Snowflake's [Parallel Hyperparameter Optimization](https://docs.snowflake.com/en/developer-guide/snowflake-ml/container-hpo)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e068d-7e1d-4c74-8289-d03ea8ab3c7e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "setup_x_and_y"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(\"MORTGAGERESPONSE\", \"TIMESTAMP\", \"LOAN_ID\")\n",
    "y_train = train.select(\"MORTGAGERESPONSE\")\n",
    "X_test = test.drop(\"MORTGAGERESPONSE\",\"TIMESTAMP\", \"LOAN_ID\")\n",
    "y_test = test.select(\"MORTGAGERESPONSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33d920-df23-4468-8d70-b03b5ad29b96",
   "metadata": {
    "collapsed": false,
    "name": "md_hpo_config"
   },
   "source": [
    "We first ingest data from the Snowpark dataframes through the Container Runtime DataConnector API. Then, we define a training function that creates an XGBoost model. The Tuner interface provides the tuning functionality, based on the given training function and search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff76e05-38f5-47cf-ab5d-9eefed09bd71",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_hpo_config"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.data import DataConnector\n",
    "from snowflake.ml.modeling.tune import get_tuner_context\n",
    "from snowflake.ml.modeling import tune\n",
    "from entities import search_algorithm\n",
    "\n",
    "# Define dataset map\n",
    "dataset_map = {\n",
    "    \"x_train\": DataConnector.from_dataframe(X_train),\n",
    "    \"y_train\": DataConnector.from_dataframe(y_train),\n",
    "    \"x_test\": DataConnector.from_dataframe(X_test),\n",
    "    \"y_test\": DataConnector.from_dataframe(y_test)\n",
    "    }\n",
    "\n",
    "\n",
    "# Define a training function, with any models you choose within it.\n",
    "def train_func():\n",
    "    # A context object provided by HPO API to expose data for the current HPO trial\n",
    "    tuner_context = get_tuner_context()\n",
    "    config = tuner_context.get_hyper_params()\n",
    "    dm = tuner_context.get_dataset_map()\n",
    "\n",
    "    model = XGBClassifier(**config, random_state=42)\n",
    "    model.fit(dm[\"x_train\"].to_pandas().sort_index(), dm[\"y_train\"].to_pandas().sort_index())\n",
    "    f1_metric = f1_score(\n",
    "        dm[\"y_train\"].to_pandas().sort_index(), model.predict(dm[\"x_train\"].to_pandas().sort_index())\n",
    "    )\n",
    "    tuner_context.report(metrics={\"f1_score\": f1_metric}, model=model)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    train_func=train_func,\n",
    "    search_space={\n",
    "        \"max_depth\": tune.randint(1, 20),\n",
    "        \"learning_rate\": tune.uniform(0.01, 0.1),\n",
    "        \"n_estimators\": tune.randint(50, 100),\n",
    "    },\n",
    "    tuner_config=tune.TunerConfig(\n",
    "        metric=\"f1_score\",\n",
    "        mode=\"max\",\n",
    "        search_alg=search_algorithm.RandomSearch(random_state=101),\n",
    "        num_trials=8, #run 8 trial runs\n",
    "        max_concurrent_trials=4, #use 4 gpus concurrently\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b5dac5-801d-4a4a-9a0c-b00050ce1138",
   "metadata": {
    "collapsed": false,
    "name": "md_run_hpo"
   },
   "source": [
    "Now, we can run the Tuner and get the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b88e99-9d2a-44cd-81f9-d53fd1321daf",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "run_hpo"
   },
   "outputs": [],
   "source": [
    "# Snowflake HPO in PrPr is single node, ensure ray context only knows of head node.\n",
    "tuner_results = tuner.run(dataset_map=dataset_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee37c42-3de7-476a-b7c0-d56952dac385",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "inspect_hpo_params"
   },
   "outputs": [],
   "source": [
    "tuned_model = tuner_results.best_model\n",
    "tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9674ca9-19ad-46ec-ad19-49a27db8958f",
   "metadata": {
    "collapsed": false,
    "name": "md_metrics"
   },
   "source": [
    "Let's compute the train and test metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4a6c2-674e-4d02-afdb-8ebf10cffdc4",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "compute_hpo_train_predictions_and_metrics"
   },
   "outputs": [],
   "source": [
    "#Generate predictions\n",
    "xgb_opt_preds = tuned_model.predict(train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n",
    "\n",
    "#Generate performance metrics\n",
    "f1_opt_train = round(f1_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\n",
    "precision_opt_train = round(precision_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\n",
    "recall_opt_train = round(recall_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\n",
    "\n",
    "print(f'Train Results: \\nF1: {f1_opt_train} \\nPrecision {precision_opt_train} \\nRecall: {recall_opt_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee80c48-d521-4b77-8841-54ba35ecd4b6",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "compute_hpo_test_predictions_and_metrics"
   },
   "outputs": [],
   "source": [
    "#Generate test predictions\n",
    "xgb_opt_preds_test = tuned_model.predict(test_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n",
    "\n",
    "#Generate performance metrics on test data\n",
    "f1_opt_test = round(f1_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n",
    "precision_opt_test = round(precision_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n",
    "recall_opt_test = round(recall_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n",
    "\n",
    "print(f'Test Results: \\nF1: {f1_opt_test} \\nPrecision {precision_opt_test} \\nRecall: {recall_opt_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1a670-52e3-4d77-ac3a-db830e22fdcf",
   "metadata": {
    "collapsed": false,
    "name": "md_hpo_perf_reaction"
   },
   "source": [
    "We see the HPO model has a more modest train accuracy than our base model, but the peformance doesn't drop off during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501cf7d-4965-4b9f-8b16-edab897d0e18",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "log_hpo_model"
   },
   "outputs": [],
   "source": [
    "#Log the optimized model to the model registry\n",
    "optimized_version_name = 'XGB_Optimized'\n",
    "\n",
    "try:\n",
    "    mv_opt = model_registry.get_model(model_name).version(optimized_version_name)\n",
    "    print(\"Found existing model version!\")\n",
    "except:\n",
    "    print(\"Logging new model version...\")\n",
    "    mv_opt = model_registry.log_model(\n",
    "        model_name=model_name,\n",
    "        model=tuned_model, \n",
    "        version_name=optimized_version_name,\n",
    "        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100),\n",
    "        comment = \"snow ml model built off feature store using HPO model\",\n",
    "        options = {'relax_version': True},\n",
    "        target_platforms={\"WAREHOUSE\"}\n",
    "    )\n",
    "    mv_opt.set_metric(metric_name=\"Train_F1_Score\", value=f1_opt_train)\n",
    "    mv_opt.set_metric(metric_name=\"Train_Precision_Score\", value=precision_opt_train)\n",
    "    mv_opt.set_metric(metric_name=\"Train_Recall_score\", value=recall_opt_train)\n",
    "\n",
    "    mv_opt.set_metric(metric_name=\"Test_F1_Score\", value=f1_opt_test)\n",
    "    mv_opt.set_metric(metric_name=\"Test_Precision_Score\", value=precision_opt_test)\n",
    "    mv_opt.set_metric(metric_name=\"Test_Recall_score\", value=recall_opt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3995f76-9543-4265-9296-2da1fa5bc2e7",
   "metadata": {
    "collapsed": false,
    "name": "md_cur_default"
   },
   "source": [
    "Let's check what our default model version is in our Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c028b9-b590-45b4-9884-35ee206bca0d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "inspect_current_default_version"
   },
   "outputs": [],
   "source": [
    "# Here we see the BASE version is our default version\n",
    "model_registry.get_model(model_name).default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ba39f-c883-47a9-9f1f-f5ec6f738ed9",
   "metadata": {
    "collapsed": false,
    "name": "md_opt_prod"
   },
   "source": [
    "Let's make this optimized model the default version instead and also set it as our `PROD` version using tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac97a9-7af4-4331-bb0d-cf6ecc4a77f6",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "promote_optimized_version_to_default"
   },
   "outputs": [],
   "source": [
    "# Now we'll set the optimized model to be the default model version going forward\n",
    "model_registry.get_model(model_name).default = optimized_version_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04efcee-27e6-4423-b669-849bec7cc8fb",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "see_updated_model_versions"
   },
   "outputs": [],
   "source": [
    "# Now we see our optimized version we have now recently promoted to our DEFAULT model version\n",
    "model_registry.get_model(model_name).default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc92f7f-5f02-4cc5-82d0-758f65f2d485",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "update_model_tags"
   },
   "outputs": [],
   "source": [
    "# We'll now update the PROD tagged model to be the optimized model version \n",
    "# rather than our overfit base version\n",
    "m.unset_tag(\"DEV\")\n",
    "m.set_tag(\"PROD\", optimized_version_name)\n",
    "m.show_tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fff15e-5f49-4d4f-a02a-93e8f3114b11",
   "metadata": {
    "collapsed": false,
    "name": "md_explainability"
   },
   "source": [
    "### Now that we've deployed some model versions and tested inference...\n",
    "\n",
    "### Let's explain our models!\n",
    "- ### Snowflake offers [built in explainability capabilities](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/model-explainability) on top of models logged to the model registry\n",
    "- ### In the below section we'll generate shapley values using these built in functions to understand how input features impact our model's behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f5cd6-d254-42d4-a0be-9848c9d09d4a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "compute_shap_vals",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Create a sample of 1000 records\n",
    "test_pd_sample = test_pd.rename(columns=rename_dict).sample(n=1000, random_state = 100).reset_index(drop=True)\n",
    "\n",
    "# Compute shapley values for each model\n",
    "base_shap_pd = mv_base.run(test_pd_sample, function_name=\"explain\")\n",
    "opt_shap_pd = mv_opt.run(test_pd_sample, function_name=\"explain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b23f4e7-f686-41c7-9a4d-94b91db8559c",
   "metadata": {
    "collapsed": false,
    "name": "md_summary_plot"
   },
   "source": [
    "We can take a look at the summary plot to understand how important each feature is to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e0dcc-a850-474a-b475-f05a77619731",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "base_shap_summary_plot",
    "resultHeight": 571
   },
   "outputs": [],
   "source": [
    "import shap \n",
    "\n",
    "shap.summary_plot(np.array(base_shap_pd.astype(float)), \n",
    "                  test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1), \n",
    "                  feature_names = test_pd_sample.drop([\"LOAN_ID\",\"MORTGAGERESPONSE\", \"TIMESTAMP\"], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0d4c3-750c-4ae0-9812-85b677db6986",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_all_shap_dfs"
   },
   "outputs": [],
   "source": [
    "# Merge shap vals and actual vals together for easier plotting below\n",
    "all_shap_base = test_pd_sample.merge(base_shap_pd, right_index=True, left_index=True, how='outer')\n",
    "all_shap_opt = test_pd_sample.merge(opt_shap_pd, right_index=True, left_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17fd593-eef5-4c52-88d3-827265017d9c",
   "metadata": {
    "collapsed": false,
    "name": "md_plot"
   },
   "source": [
    "We can also create plots to dive deeper into the feature influence in our 2 logged models.\n",
    "\n",
    "We will create 2 plot functions and then apply them to the features we want to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7036fc-b32a-43d0-87cf-9f5336eeee16",
   "metadata": {
    "language": "python",
    "name": "plot_functions"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_influence_by_model(data, X, Y, title):\n",
    "    # Set up the figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    # Plot side-by-side boxplots\n",
    "    sns.scatterplot(data = data, x = X, y = Y, ax=axes[0])\n",
    "    sns.regplot(data = data, x = X, y = Y, scatter=False, color='red', line_kws={\"lw\":2},ci =100, lowess=False, ax =axes[0])\n",
    "    \n",
    "    axes[0].set_title('Base Model')\n",
    "    sns.scatterplot(data = data, x = X, y = Y, color = \"orange\", ax = axes[1])\n",
    "    sns.regplot(data = data, x = X, y = Y, scatter=False, color='blue', line_kws={\"lw\":2},ci =100, lowess=False, ax =axes[1])\n",
    "    axes[1].set_title('Opt Model')\n",
    "    \n",
    "    # Customize and show the plot\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"Income\")\n",
    "        ax.set_ylabel(\"Influence\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_boxplot_by_model(data, X, Y, title):\n",
    "    # Set up the figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    # Plot side-by-side boxplots\n",
    "    sns.boxplot(data = data, x = X, y = Y,\n",
    "                hue=X, width=0.8, ax=axes[0])\n",
    "    axes[0].set_title('Base Model')\n",
    "    sns.boxplot(data = data, x = X, y = Y,\n",
    "                hue=X, width=0.4, ax = axes[1])\n",
    "    axes[1].set_title('Opt Model')\n",
    "    \n",
    "    # Customize and show the plot\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"(1 = True)\")\n",
    "        ax.set_ylabel(\"Influence\")\n",
    "        ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938441fd-9ae3-4f97-9a54-b7e4c74738ac",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "plot_income_loan_amt"
   },
   "outputs": [],
   "source": [
    "# Income\n",
    "\n",
    "# Filter data down to strip outliers\n",
    "asb_filtered = all_shap_base[(all_shap_base.INCOME>0) & (all_shap_base.INCOME<250000)]\n",
    "aso_filtered = all_shap_opt[(all_shap_opt.INCOME>0) & (all_shap_opt.INCOME<250000)]\n",
    "\n",
    "plot_feature_influence_by_model(asb_filtered, 'INCOME', 'INCOME_explanation', \n",
    "                                \"INCOME EXPLANATION\")\n",
    "\n",
    "# Loan Amount\n",
    "\n",
    "# Filter data down to strip outliers\n",
    "asb_filtered = all_shap_base[all_shap_base.LOAN_AMOUNT<2000000]\n",
    "aso_filtered = all_shap_opt[all_shap_opt.LOAN_AMOUNT<2000000]\n",
    "\n",
    "plot_feature_influence_by_model(asb_filtered, 'LOAN_AMOUNT', 'LOAN_AMOUNT_explanation', \n",
    "                                \"LOAN_AMOUNT EXPLANATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a03aa9-1f1a-4a4e-809e-b22e438d72aa",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "plot_home_purchase_improvement",
    "resultHeight": 851
   },
   "outputs": [],
   "source": [
    "plot_boxplot_by_model(all_shap_base, \n",
    "                      \"LOAN_PURPOSE_NAME_HOME_PURCHASE\",\n",
    "                      \"LOAN_PURPOSE_NAME_HOME_PURCHASE_explanation\",\n",
    "                      \"HOME PURCHASE LOAN EXPLANATION\")\n",
    "\n",
    "plot_boxplot_by_model(all_shap_base, \n",
    "                      \"LOAN_PURPOSE_NAME_HOME_IMPROVEMENT\",\n",
    "                      \"LOAN_PURPOSE_NAME_HOME_IMPROVEMENT_explanation\",\n",
    "                      \"HOME IMPROVEMENT LOAN EXPLANATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a9ccc-e785-4a82-b9e9-97fd44d5acf2",
   "metadata": {
    "collapsed": false,
    "name": "md_monitoring",
    "resultHeight": 74
   },
   "source": [
    "# Model Observability (Model Monitoring)\n",
    "\n",
    "[ML Observability](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/model-observability) allows you to track the quality of production models you have deployed via the Snowflake Model Registry across multiple dimensions, such as performance, drift, and volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797947d-81f4-4c72-a94f-47d1b7ed397f",
   "metadata": {
    "collapsed": false,
    "name": "md_tables_stage"
   },
   "source": [
    "Let's first save our train and test data as Snowflake tables and create a new stage for the next few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0751bdd-6c24-4c65-9247-aa90ebc1d376",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_table_from_test_data",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "train.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TRAIN_{VERSION_NUM}\", mode=\"overwrite\")\n",
    "test.write.save_as_table(f\"DEMO_MORTGAGE_LENDING_TEST_{VERSION_NUM}\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabdf2be-87f8-4556-aa42-22e4a70515e1",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_stage",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "session.sql(\"CREATE STAGE IF NOT EXISTS ML_STAGE\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82415154-e85c-4950-97f2-bfa282525d2e",
   "metadata": {
    "collapsed": false,
    "name": "md_sprocs"
   },
   "source": [
    "We can create stored procedures for running model inference. These procedures can be scheduled or orchestrated to run continuous inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2c090-5cc8-4847-982a-fb9b5e427616",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "define_sproc",
    "resultHeight": 495
   },
   "outputs": [],
   "source": [
    "from snowflake import snowpark\n",
    "from snowflake.ml.registry import Registry\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "import snowflake.ml.modeling.preprocessing as pp\n",
    "from snowflake.snowpark.types import StringType, IntegerType\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "\n",
    "def demo_inference_sproc(session: snowpark.Session, table_name: str, modelname: str, modelversion: str) -> str:\n",
    "    database=session.get_current_database()\n",
    "    schema=session.get_current_schema()\n",
    "    reg = Registry(session=session)\n",
    "    m = reg.get_model(model_name)  # Fetch the model using the registry\n",
    "    mv = m.version(modelversion)\n",
    "    \n",
    "    input_table_name=table_name\n",
    "    pred_col = f'{modelversion}_PREDICTION'\n",
    "\n",
    "    # Read the input table to a dataframe\n",
    "    df = session.table(input_table_name)\n",
    "    # 'results' is the output DataFrame with predictions\n",
    "    results = mv.run(df, function_name=\"predict\").select(\"LOAN_ID\",'\"output_feature_0\"').withColumnRenamed('\"output_feature_0\"', pred_col)\n",
    "\n",
    "    final = df.join(results, on=\"LOAN_ID\", how=\"full\")\n",
    "    \n",
    "    # Write results back to Snowflake table\n",
    "    final.write.save_as_table(table_name, mode='overwrite',enable_schema_evolution=True)\n",
    "\n",
    "    return \"Success\"\n",
    "\n",
    "# Register the stored procedure\n",
    "session.sproc.register(\n",
    "    func=demo_inference_sproc,\n",
    "    name=\"model_inference_sproc\",\n",
    "    replace=True,\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@ML_STAGE\",\n",
    "    packages=['joblib', 'snowflake-snowpark-python', 'snowflake-ml-python'],\n",
    "    return_type=StringType()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c672aa3-70eb-41fa-a0cb-06fdee6ca1d7",
   "metadata": {
    "collapsed": false,
    "name": "md_call_sprocs"
   },
   "source": [
    "We'll call our stored procedure 4 times which will execute inference using our 2 models (base and HPO optimized) on our train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45031a-917e-4f6d-a2e4-068879791819",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "gb_base_train_inference",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc(\n",
    "    'DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}',\n",
    "    '{{model_name}}', \n",
    "    '{{base_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18ea05-7d29-43a3-9baa-52509f3bb15e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "gb_base_test_inference",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc(\n",
    "    'DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}',\n",
    "    '{{model_name}}', \n",
    "    '{{base_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2550b-46c7-4eb7-adaa-64c345711b1e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "gb_opt_train_inference",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc(\n",
    "    'DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}',\n",
    "    '{{model_name}}', \n",
    "    '{{optimized_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245f482-19e9-4961-9cb2-801bf5948d52",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "gb_opt_test_inference",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc(\n",
    "    'DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}',\n",
    "    '{{model_name}}', \n",
    "    '{{optimized_version_name}}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78728593-1cb0-4d1a-b06c-e2e5f21c38c9",
   "metadata": {
    "collapsed": false,
    "name": "md_see_preds"
   },
   "source": [
    "We can take a look at our predictions now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05048c-a9d1-4ef9-bf39-5333f3fb56cb",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "see_preds",
    "resultHeight": 251
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}} LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d835b6b0-ab3b-4b7f-84d5-fb17a2805321",
   "metadata": {
    "collapsed": false,
    "name": "md_create_monitors"
   },
   "source": [
    "### Create Model Monitors\n",
    "\n",
    "We'll now create model monitors for both the base and HPO optimized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6be548-47cb-4a91-92ee-a5f42c41e756",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "create_model_monitor_tree_SQL",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_BASE_MODEL_MONITOR\n",
    "WITH\n",
    "    MODEL={{model_name}}\n",
    "    VERSION={{base_version_name}}\n",
    "    FUNCTION=predict\n",
    "    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n",
    "    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n",
    "    TIMESTAMP_COLUMN=TIMESTAMP\n",
    "    PREDICTION_CLASS_COLUMNS=(XGB_BASE_PREDICTION)  \n",
    "    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n",
    "    ID_COLUMNS=(LOAN_ID)\n",
    "    WAREHOUSE={{session.get_current_warehouse()}}\n",
    "    REFRESH_INTERVAL='1 min'\n",
    "    AGGREGATION_WINDOW='1 day';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60965976-f17f-42bc-92ae-e43030bba54e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "create_model_monitor_linear_SQL",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_OPTIMIZED_MODEL_MONITOR\n",
    "WITH\n",
    "    MODEL={{model_name}}\n",
    "    VERSION={{optimized_version_name}}\n",
    "    FUNCTION=predict\n",
    "    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n",
    "    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n",
    "    TIMESTAMP_COLUMN=TIMESTAMP\n",
    "    PREDICTION_CLASS_COLUMNS=(XGB_OPTIMIZED_PREDICTION)  \n",
    "    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n",
    "    ID_COLUMNS=(LOAN_ID)\n",
    "    WAREHOUSE={{session.get_current_warehouse()}}\n",
    "    REFRESH_INTERVAL='1 min'\n",
    "    AGGREGATION_WINDOW='1 day';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288cc48-c890-4d4a-96d1-07f1986d2348",
   "metadata": {
    "collapsed": false,
    "name": "md_pred_drift"
   },
   "source": [
    "We can also compute the prediction drift using the Model Monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fc658-38f4-4c9a-980b-cf40ef61a268",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "compute_prediction_drift"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n",
    "'MORTGAGE_LENDING_OPTIMIZED_MODEL_MONITOR', 'DIFFERENCE_OF_MEANS', 'XGB_BASE_PREDICTION', '1 DAY', TO_TIMESTAMP_TZ('2024-06-01'), TO_TIMESTAMP_TZ('2024-09-01')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000036",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "name": "conclusion",
    "resultHeight": 202,
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "#### 🛠️ Snowflake Feature Store tracks feature definitions and maintains lineage of sources and destinations 🛠️\n",
    "#### 🚀 Snowflake Model Registry gives users a secure and flexible framework to deploy track and monitor models 🚀\n",
    "#### 🔮 All model versions logged in the Model Registry can be accessed for inference, explainability, lineage tracking, visibility and more 🔮\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f44c10-7b1d-48f1-95f4-ffadb23b0a4e",
   "metadata": {
    "collapsed": false,
    "name": "md_dist_train_deploy"
   },
   "source": [
    "# [Optional] Distributed model training & deployment\n",
    "\n",
    "For demonstrations sake, below we have an example doing distributed model training using Snowflake's [distributed modeling classes](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/modeling_distributors).\n",
    "\n",
    "Snowflake will set up a ray cluster on all available nodes in your compute pool (CPU or GPU) and execute the distributed training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a41b0b-e15a-4bc9-ba05-c3d594b16ab6",
   "metadata": {
    "collapsed": false,
    "name": "md_dist_train"
   },
   "source": [
    "For the first example, we will run single node, multi-GPU distributed XGBoost training.\n",
    "\n",
    "We can go ahead and specify a scaling config (using `XGBScalingConfig`), define the distributed xgb estimator (`XGBEstimator`), and run the fit to kick of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e2451-0614-4c72-b75f-ad0d86ba9798",
   "metadata": {
    "language": "python",
    "name": "dist_train"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.distributors.xgboost.xgboost_estimator import XGBEstimator, XGBScalingConfig\n",
    "from snowflake.ml.data.data_connector import DataConnector\n",
    "\n",
    "# Use Snowflake's DataConnector to efficiently connect Snowflake data to Ray\n",
    "dc = DataConnector.from_dataframe(train)\n",
    "\n",
    "# Set up the scaling configuration for multi-node and multi-GPU usage\n",
    "scaling_config = XGBScalingConfig(\n",
    "    num_workers=-1,            # Use all available workers\n",
    "    num_cpu_per_worker=-1,     # Use all available CPU cores per worker\n",
    "    use_gpu=True               # Enable GPU for training, resources_per_worker={\"GPU\": 1}\n",
    ")\n",
    "\n",
    "# Define distributed xgb estimator\n",
    "dist_gpu_xgb = XGBEstimator(\n",
    "    params = {\"booster\": \"gbtree\",\n",
    "              \"n_estimators\":10,},\n",
    "    scaling_config = scaling_config)\n",
    "\n",
    "dist_gpu_xgb.fit(dc,\n",
    "                 input_cols = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).columns,\n",
    "                 label_col = \"MORTGAGERESPONSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac77dd-ab68-4398-b289-1c44d61b1f9c",
   "metadata": {
    "collapsed": false,
    "name": "md_extract_xgb_booster"
   },
   "source": [
    "We will need to extract the xgb booster object from the Snowflake optimized XGB model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903e6a2-62ab-4365-8a98-501b7bdf3375",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "get_booster"
   },
   "outputs": [],
   "source": [
    "# Extract xgb booster object from Snowflake optimized XGB model\n",
    "gpu_booster = dist_gpu_xgb.get_booster()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef9ff0-e9ab-40ca-97bc-b59e7450c369",
   "metadata": {
    "collapsed": false,
    "name": "md_dist_model"
   },
   "source": [
    "Now we can log the distributed xgb model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce6d1f-8025-435e-afcd-e2c597d24904",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "log_dist_model"
   },
   "outputs": [],
   "source": [
    "# Log the distributed model to the model registry\n",
    "dist_version_name = 'XGB_GPU_DIST'\n",
    "\n",
    "try:\n",
    "    mv_base = model_registry.get_model(model_name).version(dist_version_name)\n",
    "    print(\"Found existing model version!\")\n",
    "except:\n",
    "    print(\"Logging new model version...\")\n",
    "    mv_base = model_registry.log_model(\n",
    "        model_name=model_name,\n",
    "        model=gpu_booster,\n",
    "        version_name=dist_version_name,\n",
    "        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100), #using snowpark df to maintain lineage\n",
    "        comment = \"\"\"Distributed ML model for predicting loan approval likelihood.\"\"\",\n",
    "        options={'relax_version': True},\n",
    "        target_platforms={\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202de854-c08f-4146-b898-2a6209f64573",
   "metadata": {
    "collapsed": false,
    "name": "md_multinode"
   },
   "source": [
    "Now, we will scale our resources to run multi-node, multi-GPU distributed XGBoost training.\n",
    "\n",
    "To see the available GPU resources, we will create a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb1b94-1cfd-4c5e-8a62-3e3b4b1b9c07",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "_ray_resource"
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import pprint\n",
    "\n",
    "def _format_resources(resources):\n",
    "    \"\"\"Convert memory fields to GB and filter out internal node tags.\"\"\"\n",
    "    formatted = {}\n",
    "    for k, v in resources.items():\n",
    "        # Skip internal node identifiers\n",
    "        if k.startswith(\"node:\"):\n",
    "            continue\n",
    "        if k in {\"memory\", \"object_store_memory\"}:\n",
    "            formatted[k] = f\"{v / (1024 ** 3):.2f} GB\"\n",
    "        else:\n",
    "            formatted[k] = v\n",
    "    return formatted\n",
    "\n",
    "def show_ray_cluster_resources():\n",
    "    \"\"\"Nicely formatted cluster-wide and node-level resource info from Ray.\"\"\"\n",
    "    print(\" Cluster Resources:\")\n",
    "    cluster = _format_resources(ray.cluster_resources())\n",
    "    pprint.pprint(cluster, sort_dicts=True, width=100)\n",
    "\n",
    "    print(\"\\n Node-Level Resources:\")\n",
    "    for node in ray.nodes():\n",
    "        print(f\"\\nNode: {node['NodeManagerAddress']}\")\n",
    "        node_resources = _format_resources(node[\"Resources\"])\n",
    "        pprint.pprint(node_resources, sort_dicts=True, width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ddbd3-8a64-4915-955b-3d92b4cac91a",
   "metadata": {
    "collapsed": false,
    "name": "md_single_node"
   },
   "source": [
    "As expected, we're only seeing a single node right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb68e91-8ce0-49c5-bc9b-87eb83151c2b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "show_nodes_gpus"
   },
   "outputs": [],
   "source": [
    "show_ray_cluster_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf3e6b-cf17-446b-866d-f98dabc49c1b",
   "metadata": {
    "collapsed": false,
    "name": "md_scale_up"
   },
   "source": [
    "Let's scale our resources to use all 4 nodes in our cluster using Snowflake ML's `scale_cluster` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31149b3-eaa1-4828-9096-e755fff4b932",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "scale_up_cluster_pretrain"
   },
   "outputs": [],
   "source": [
    "# Scale to max compute pool nodes\n",
    "num_nodes = 4\n",
    "\n",
    "# Suppress SIGTERM ray warnings \n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Use full path name\n",
    "nb_name = \"E2E_ML_NOTEBOOK\"\n",
    "scale_cluster(expected_cluster_size=num_nodes, \n",
    "              notebook_name=nb_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89eaca3-7cd9-4ea4-b1bf-1162c5e43fc6",
   "metadata": {
    "collapsed": false,
    "name": "md_4_nodes"
   },
   "source": [
    "We should see details for all 4 nodes now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfc050-c294-4843-ba42-d3e784ce1644",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "confirm_scale_up"
   },
   "outputs": [],
   "source": [
    "# Show number of nodes after changing cluster manager settings\n",
    "show_ray_cluster_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74fdb36-84bd-46fb-a9c0-5599b7ae61cb",
   "metadata": {
    "collapsed": false,
    "name": "md_ready_to_train"
   },
   "source": [
    "Now, we're ready to do multi-node, multi-GPU training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c59691b-d866-452b-955b-1ef03ea42df6",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "quiet_ray_pretrain"
   },
   "outputs": [],
   "source": [
    "# Quiet messages from Ray\n",
    "context = ray.data.DataContext().get_current() \n",
    "context.execution_options.verbose_progress = False\n",
    "# context.enable_operator_progress_bars = False\n",
    "# context.enable_progress_bars = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44106da8-2fff-4494-94d4-7122f3007895",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "multi_node_multi_gpu"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.distributors.xgboost.xgboost_estimator import XGBEstimator, XGBScalingConfig\n",
    "from snowflake.ml.data.data_connector import DataConnector\n",
    "\n",
    "# Use Snowflake's DataConnector to efficiently connect Snowflake data to Ray\n",
    "dc = DataConnector.from_dataframe(train)\n",
    "\n",
    "# Set up the scaling configuration for multi-node and multi-GPU usage\n",
    "scaling_config = XGBScalingConfig(\n",
    "    num_workers=-1,            # Use all available workers\n",
    "    num_cpu_per_worker=-1,     # Use all available CPU cores per worker\n",
    "    use_gpu=True               # Enable GPU for training, resources_per_worker={\"GPU\": 1}\n",
    ")\n",
    "\n",
    "# Define XGBoost hyperparameters for GPU\n",
    "hyp_params = {\n",
    "    \"booster\": \"gbtree\",               # Standard boosting model\n",
    "    \"tree_method\": \"gpu_hist\",         # Enables NV_GPU Histogram\n",
    "    \"predictor\": \"auto\",               # Uses GPU for prediction\n",
    "    \"n_estimators\": 100,               # Number of trees to train\n",
    "    \"max_depth\": 0,                    # Maximum tree depth\n",
    "    \"grow_policy\": \"lossguide\",        # Enables better GPU scalability by growing trees leaf-wise (instead of depth-wise)\n",
    "    \"max_leaves\": 512,                 # Limits tree complexity; balances model capacity and memory usage when using 'lossguide'\n",
    "    \"learning_rate\": 0.1,              # Step size for each tree\n",
    "    \"subsample\": 0.8,                  # Fraction of samples used for each tree\n",
    "    \"colsample_bytree\": 0.8            # Fraction of features used for each tree\n",
    "}\n",
    "\n",
    "# Define distributed xgb estimator\n",
    "multi_node_gpu_xgb = XGBEstimator(\n",
    "    params = hyp_params,\n",
    "    scaling_config = scaling_config)\n",
    "\n",
    "multi_node_gpu_xgb.fit(dc,\n",
    "                 input_cols = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).columns,\n",
    "                 label_col = \"MORTGAGERESPONSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b7cc9-889b-4b49-9799-88d852440d3a",
   "metadata": {
    "collapsed": false,
    "name": "md_log_last_model"
   },
   "source": [
    "As before, let's log this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a3b58-42e4-4883-aac2-d680b5830a16",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "log_multi_node_xgb"
   },
   "outputs": [],
   "source": [
    "# Extract xgb booster object from Snowflake optimized XGB model\n",
    "gpu_booster = multi_node_gpu_xgb.get_booster()\n",
    "\n",
    "# Log the distributed model to the model registry\n",
    "dist_version_name = 'XGB_MULTI_NODE_GPU_DIST'\n",
    "\n",
    "try:\n",
    "    mv_base = model_registry.get_model(model_name).version(dist_version_name)\n",
    "    print(\"Found existing model version!\")\n",
    "except:\n",
    "    print(\"Logging new model version...\")\n",
    "    mv_base = model_registry.log_model(\n",
    "        model_name=model_name,\n",
    "        model=gpu_booster,\n",
    "        version_name=dist_version_name,\n",
    "        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100), #using snowpark df to maintain lineage\n",
    "        comment = \"\"\"Distributed ML model for predicting loan approval likelihood.\"\"\",\n",
    "        options={'relax_version': True},\n",
    "        target_platforms={\"SNOWPARK_CONTAINER_SERVICES\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a208883-0e48-4685-ac30-0e23c3cbfab6",
   "metadata": {
    "language": "sql",
    "name": "show_versions"
   },
   "outputs": [],
   "source": [
    "SHOW VERSIONS IN MODEL {{model_name}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5893460-f5ee-4e3a-8798-bbb15300f19c",
   "metadata": {
    "collapsed": false,
    "name": "md_show_models_2"
   },
   "source": [
    "We can take a look at all our models now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df060c3-a45b-4999-b229-18cfdeec492c",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "show_models_2"
   },
   "outputs": [],
   "source": [
    "model_registry.show_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3934427e-390d-4f5d-b341-756afa53f8c2",
   "metadata": {
    "collapsed": false,
    "name": "md_scale_down"
   },
   "source": [
    "Since we don't need all nodes anymore, let's scale down our cluster now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f3de4-685f-402f-8caa-427cdb56938b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "scale_down_post_train"
   },
   "outputs": [],
   "source": [
    "# Scale down \n",
    "num_nodes = 1\n",
    "\n",
    "# Suppress SIGTERM ray warnings \n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Use full path\n",
    "nb_name = \"E2E_ML_NOTEBOOK\"\n",
    "scale_cluster(expected_cluster_size=num_nodes, \n",
    "              notebook_name=nb_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c96e53-480c-4df4-8375-e0ad5faec722",
   "metadata": {
    "collapsed": false,
    "name": "md_confirm_scale_down"
   },
   "source": [
    "We can see that 3 of the nodes are empty now, which tells us they're not longer being considered as available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fee6a9-9265-4e2d-848d-f209ba15c891",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "confirm_scale_down"
   },
   "outputs": [],
   "source": [
    "# Show number of nodes after changing cluster manager settings\n",
    "show_ray_cluster_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8deb6-fdc0-464d-9ad2-b41650a2217a",
   "metadata": {
    "collapsed": false,
    "name": "model_deploy_spcs"
   },
   "source": [
    "## Model Deployment to Snowpark Container Services (SPCS)\n",
    "\n",
    "Here, we also show how to deploy a model to Snowpark Container Services as a long running service using [Model Serving](https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/container).\n",
    "\n",
    "This is useful to run GPU based inference, run very large models that do not fit in the Warehouse memory, or when you have additional package dependencies that are not met in the Warehouse. You can also create REST API endpoints for running inference using external HTTP requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238010f9-396a-4ca7-97b7-8ab166d05b6f",
   "metadata": {
    "collapsed": false,
    "name": "md_define_vars"
   },
   "source": [
    "Let's first define the variables we'll use to create the deployment service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15be76d-6afe-4020-950c-0e8cc3955a66",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "define_deploy_vars"
   },
   "outputs": [],
   "source": [
    "image_repo_name = \"my_inference_images\"\n",
    "# cp_name = \"CP_GPU_NV_S_1_4\"\n",
    "\n",
    "cp_name = \"CP_GPU_NV_S_4\"\n",
    "num_spcs_nodes = '2'\n",
    "service_name = 'MORTGAGE_LENDING_PREDICTION_SERVICE'\n",
    "\n",
    "current_database = session.get_current_database().replace('\"', '')\n",
    "current_schema = session.get_current_schema().replace('\"', '')\n",
    "extended_image_repo_name = f\"{current_database}.DEFAULT_SCHEMA.{image_repo_name}\"\n",
    "extended_service_name = f'{current_database}.DEFAULT_SCHEMA.{service_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88db88-6d30-4ca5-aedb-700ab5609c8a",
   "metadata": {
    "language": "sql",
    "name": "drop_if_needed"
   },
   "outputs": [],
   "source": [
    "DROP SERVICE IF EXISTS {{service_name}};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca8088c-7a3e-4d65-b669-dae3eafc907d",
   "metadata": {
    "collapsed": false,
    "name": "md_create_service"
   },
   "source": [
    "Note, we're creating a service based on the model we just logged to the Model Registry: `mv_base`\n",
    "\n",
    "You can also specify pip_requirements if your model has pip dependencies. Here we are selecting `ingress_enabled = True` to also create a REST API endpoint for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96365088-1841-4505-88aa-c4bd472a63ce",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "create_service"
   },
   "outputs": [],
   "source": [
    "mv_base.create_service(\n",
    "    service_name=extended_service_name,\n",
    "    service_compute_pool=cp_name,\n",
    "    image_repo=extended_image_repo_name,\n",
    "    ingress_enabled=True,\n",
    "    max_instances=int(num_spcs_nodes),\n",
    "    build_external_access_integration=\"ALLOW_ALL_INTEGRATION\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57963a21-c131-4a05-8f50-e878e1cc3950",
   "metadata": {
    "collapsed": false,
    "name": "md_check_services"
   },
   "source": [
    "Now, we can check that the service is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04424bbb-33af-4c91-a3d7-e6294c9b6d78",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "show_services"
   },
   "outputs": [],
   "source": [
    "SHOW SERVICES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc147c6-e180-49f4-a863-f7cfe19a5668",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "get_model_services"
   },
   "outputs": [],
   "source": [
    "# mv_base = model_registry.get_model(f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\").version(\"XGB_GPU_DIST\")\n",
    "mv_base = model_registry.get_model(f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\").version(\"XGB_MULTI_NODE_GPU_DIST\")\n",
    "mv_base.list_services()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceac92c-b931-4513-ac69-0ba029ed743d",
   "metadata": {
    "collapsed": false,
    "name": "md_run_inference"
   },
   "source": [
    "Now, we can run predictions on test data using this deployed SPCS Model Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf6cd1-67e1-4638-95f8-dae3fe69dd4a",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "run_inference"
   },
   "outputs": [],
   "source": [
    "mv_base.run(test, \n",
    "            function_name = \"PREDICT\", \n",
    "            service_name = \"DEFAULT_SCHEMA.MORTGAGE_LENDING_PREDICTION_SERVICE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd35ac-cbc5-41c0-95ee-caa59aa19894",
   "metadata": {
    "collapsed": false,
    "name": "md_drop_service"
   },
   "source": [
    "Since we created a REST API above, this service will run continuously. It is a good idea to drop or suspend the service if you do not need it. Compute pool will automatically suspend if no service is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e6063-6d6e-44d3-9b68-e87ca9d5134e",
   "metadata": {
    "language": "sql",
    "name": "drop_service"
   },
   "outputs": [],
   "source": [
    "DROP SERVICE IF EXISTS {{service_name}};"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python37 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "lastEditStatus": {
   "authorEmail": "sikha.das@snowflake.com",
   "authorId": "158808794318",
   "authorName": "SIKHADAS",
   "lastEditTime": 1746106252930,
   "notebookId": "62lmf5ta26eno2ev5pbc",
   "sessionId": "68eec705-98d1-4337-97cb-173b93a38778"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
